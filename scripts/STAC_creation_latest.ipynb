{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e2fbb91",
   "metadata": {},
   "source": [
    "This code will create a STAC catalog by crawling over folders in the Cyverse Data Store and looking for geospatial assets (e.g., orthomosaics, point clouds, DEMs). \n",
    "\n",
    "Please launch 'JupyterLab_Geospatial' VICE app in Cyverse Discovery Environment\n",
    "Open this Jupyter Notebook `STAC_creation_latest.ipynb`\n",
    "Change the Kernel to `osgeo`\n",
    "Use at least 16gb of RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a4ef00a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rasterio==1.3.8 in /opt/conda/envs/osgeo/lib/python3.9/site-packages (1.3.8)\n",
      "Requirement already satisfied: shapely==2.0.1 in /opt/conda/envs/osgeo/lib/python3.9/site-packages (2.0.1)\n",
      "Requirement already satisfied: pystac==1.8.4 in /opt/conda/envs/osgeo/lib/python3.9/site-packages (1.8.4)\n",
      "Requirement already satisfied: piexif==1.1.3 in /opt/conda/envs/osgeo/lib/python3.9/site-packages (1.1.3)\n",
      "Requirement already satisfied: pandas==2.0.2 in /opt/conda/envs/osgeo/lib/python3.9/site-packages (2.0.2)\n",
      "Requirement already satisfied: geopy==2.4.0 in /opt/conda/envs/osgeo/lib/python3.9/site-packages (2.4.0)\n",
      "Requirement already satisfied: affine in /opt/conda/envs/osgeo/lib/python3.9/site-packages (from rasterio==1.3.8) (2.4.0)\n",
      "Requirement already satisfied: attrs in /opt/conda/envs/osgeo/lib/python3.9/site-packages (from rasterio==1.3.8) (23.1.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/envs/osgeo/lib/python3.9/site-packages (from rasterio==1.3.8) (2023.5.7)\n",
      "Requirement already satisfied: click>=4.0 in /opt/conda/envs/osgeo/lib/python3.9/site-packages (from rasterio==1.3.8) (8.1.7)\n",
      "Requirement already satisfied: cligj>=0.5 in /opt/conda/envs/osgeo/lib/python3.9/site-packages (from rasterio==1.3.8) (0.7.2)\n",
      "Requirement already satisfied: numpy>=1.18 in /opt/conda/envs/osgeo/lib/python3.9/site-packages (from rasterio==1.3.8) (1.24.3)\n",
      "Requirement already satisfied: snuggs>=1.4.1 in /opt/conda/envs/osgeo/lib/python3.9/site-packages (from rasterio==1.3.8) (1.4.7)\n",
      "Requirement already satisfied: click-plugins in /opt/conda/envs/osgeo/lib/python3.9/site-packages (from rasterio==1.3.8) (1.1.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/osgeo/lib/python3.9/site-packages (from rasterio==1.3.8) (67.7.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.0 in /opt/conda/envs/osgeo/lib/python3.9/site-packages (from pystac==1.8.4) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/osgeo/lib/python3.9/site-packages (from pandas==2.0.2) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/envs/osgeo/lib/python3.9/site-packages (from pandas==2.0.2) (2023.3)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in /opt/conda/envs/osgeo/lib/python3.9/site-packages (from geopy==2.4.0) (2.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/osgeo/lib/python3.9/site-packages (from python-dateutil>=2.7.0->pystac==1.8.4) (1.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.1.6 in /opt/conda/envs/osgeo/lib/python3.9/site-packages (from snuggs>=1.4.1->rasterio==1.3.8) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#Install python libraries used in this script\n",
    "%pip install rasterio==1.3.8 shapely==2.0.1 pystac==1.8.4 piexif==1.1.3 pandas==2.0.2 geopy==2.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bc23478",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########Import libraries, modules, and classes into environment. ########\n",
    "###########################\n",
    "\n",
    "#Import the Path class from the pathlib module in Python. \\\n",
    "#The pathlib module is part of the Python Standard Library and provides \\\n",
    "#an object-oriented way to work with file system paths, \\\n",
    "#making it more convenient and readable than using traditional string-based file paths.\n",
    "\n",
    "#The Path class is a high-level and flexible representation of file system paths. \\\n",
    "#It can be used for various purposes, such as constructing file system paths, navigating directories, \\\n",
    "#creating directories, reading or writing files, and more.\n",
    "from pathlib import Path\n",
    "\n",
    "#The os module is part of the Python Standard Library and provides a \\\n",
    "#collection of functions for interacting with the operating system. \n",
    "#This module allows you to perform various tasks such as creating, deleting, or modifying files and directories, \\\n",
    "#obtaining system information, and managing processes.\n",
    "import os\n",
    "\n",
    "#Import Optional typing hint\n",
    "from typing import Optional\n",
    "\n",
    "#ThreadPoolExecutor is a class from the 'concurrent.futures' module which comes from the Standard Python Library. \n",
    "#It provides a high level interface for asynchronously executing functions using threads. It can be used to execute \\\n",
    "#a certain number of functions in parallel, leveraging multiple threads. \n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "\n",
    "#Import the pystac library into environment. Pystac (https://pystac.readthedocs.io/en/stable/index.html)\n",
    "#is a library for reading and writing STAC stuff\n",
    "import pystac \n",
    "\n",
    "#ProjectionExtension is a class within the module 'pystac.extensions.projection'. \\\n",
    "#We are using it to show the map projection of raster dataset\n",
    "from pystac.extensions.projection import ProjectionExtension\n",
    "\n",
    "#RasterExtension is a class within the module 'pystac.extensions.raster'\n",
    "#we are using it to display various info about the raster\n",
    "from pystac.extensions.raster import RasterExtension\n",
    "\n",
    "\n",
    "from pystac.extensions.scientific import ScientificExtension\n",
    "from pystac.extensions.scientific import Publication\n",
    "\n",
    "from pystac.extensions.raster import RasterExtension\n",
    "\n",
    "\n",
    "from pystac.provider import Provider\n",
    "from pystac.provider import ProviderRole\n",
    "import pystac.provider \n",
    "from pystac import Provider\n",
    "\n",
    "\n",
    "#rasterio is a library to read and write raster data. It will be used in this script to extract information \\\n",
    "#from drone imagery geotiffs \n",
    "import rasterio\n",
    "import rasterio.warp #used to convert coordinate of a raster bounding box\n",
    "\n",
    "#Import the pdal lirbary into the environment. We use pdal (https://pdal.io/en/latest/) for reading LAS and LAZ files\n",
    "#pdal is installed in the osgeo kernel, so we do not 'pip install pdal' in this script\n",
    "import pdal\n",
    "\n",
    "# Used to assist with pdal work\n",
    "from osgeo import osr\n",
    "from osgeo import ogr\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "\n",
    "#Used to create a polygon of the raster bounds\n",
    "from shapely.geometry import Polygon, mapping\n",
    "\n",
    "#For creating a geojson output file of STAC items. This module comes in the Python Standard Library\n",
    "import json\n",
    "\n",
    "# datetime is a module in the Python's standard library. We need it to assign collection dates to each item or asset\n",
    "from datetime import datetime\n",
    "\n",
    "#We will use pandas to bring a csv file into a dataframe\n",
    "import pandas\n",
    "\n",
    "#We use the subprocess module when processing LAS/LAZ data. This prevents the kernel from \\\n",
    "#falsely getting flagged as unresponsive and automatically restarted (causing all work to be lost)\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49fefd24-d5e0-4ee2-a47c-83201a114d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "######This cell is for users to input manual metadata for imagery assets that will become STAC catalogs.#######\n",
    "############################\n",
    "\n",
    "#source_image_folder = '/data-store/iplant/home/jgillan/stac_test'\n",
    "#source_image_folder = '/data-store/iplant/home/shared/commons_repo/curated/Gillan_Ecosphere_2021/raster_products/May_2019'\n",
    "source_image_folder = '/data-store/iplant/home/shared/ofo/internal/david_data_for_Jeff/3_geometric-derived/metashape/reconstuction-000000/exports'\n",
    "\n",
    "# output folder (will overwrite existing files with matching output names)\n",
    "#stac_output_directory = '/data-store/iplant/home/jgillan/STAC_drone/SRER_May2019'\n",
    "#stac_output_directory = '/data-store/iplant/home/jgillan/stac_test/oct9'\n",
    "stac_output_directory = '/data-store/iplant/home/shared/ofo/internal/david_data_for_Jeff/3_geometric-derived/metashape/reconstuction-000000/exports/stac_test'\n",
    "\n",
    "# Additional Metadata to add to items\n",
    "platform = 'DJI Phantom 4 RTK'\n",
    "license = 'CC-BY-SA-4.0'\n",
    "items_mission_description = 'Open Forest Observatory Test Data'\n",
    "pub_doi = '10.1002/ecs2.3649'\n",
    "citation = 'Gillan, JK., GE Ponce-Campos, TL Swetnam, A Gorlier, P Heilman, MP McClaran. 2021. Innovations to expand drone data collection and analysis for rangeland monitoring. Ecosphere, 12(7)'\n",
    "\n",
    "# collection definitions\n",
    "collection_id = 'ofo_test' # needs to be folder-name compatible\n",
    "collection_description = 'The imagery was part of the Ecostate Mapping project of 2019 at Santa Rita Experimental Range'\n",
    "\n",
    "# top-level catalog definitions\n",
    "catalog_id = 'Cyverse Remotely Sensed Imagery STAC Catalog'\n",
    "catalog_description = 'This catalog includes all of the imagery assets the exist in Cyverse Data Store'\n",
    "\n",
    "\n",
    "# create default datetime object for the collection - used when all items were collected on same date\n",
    "default_datetime = datetime(year=2023, month=5, day=25, hour=12)\n",
    "\n",
    "#If items were collected on different dates, then you should supply a csv that has the following columns:'Id', 'collection_date'\n",
    "#df_collection_date = pandas.read_csv('/data-store/iplant/home/jgillan/stac_test/collection_date.csv')\n",
    "#df_collection_date = pandas.read_csv('/data-store/iplant/home/shared/commons_repo/curated/Gillan_Ecosphere_2021/raster_products/May_2019/srer_may2019.csv')\n",
    "#df_collection_date = pandas.read_csv('/data-store/iplant/home/shared/ofo/internal/david_data_for_Jeff/3_geometric-derived/metashape/reconstuction-000000/exports/collection_date.csv')\n",
    "df_collection_date = pandas.read_csv('/data-store/iplant/home/jgillan/collection_date.csv')\n",
    "                                                 \n",
    "#Provider information\n",
    "provider = Provider(name='Derek Young',\n",
    "                       description=\"A provider that supplies example geospatial data.\",\n",
    "                       roles=[ProviderRole.PRODUCER, ProviderRole.PROCESSOR],\n",
    "                       url='https://openforestobservatory.org/')\n",
    "\n",
    "provider_dict = provider.to_dict()\n",
    "\n",
    "#Email contact variable\n",
    "contact_email = 'djyoung@ucdavis.edu'\n",
    "\n",
    "\n",
    "# email host variables - DON'T CHANGE these unless you know what you're doing\n",
    "smtp_host = '128.196.254.80'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "551ad62e-e759-4110-9add-e5a2a1e67c84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#########Functions to extract the spatial resolution(ground sampline distance) from geotif imagery products \\\n",
    "##########These functions are using the 'rasterio' library.\n",
    "\n",
    "# function to truncate spatial resolution to 3 decimal places\n",
    "def trun_n_d(num,n):\n",
    "    num_s = str(num)\n",
    "    if 'e' in num_s or 'E' in num_s:\n",
    "        return '{0:.{1}f}'.format(num,n)\n",
    "    i,p,d = num_s.partition('.')\n",
    "    return '.'.join([i,(d+'0'*n)[:n]])\n",
    "\n",
    "# function to get the spatial resolution of a raster. It only works if the imagery products has a map projection, otherwise \n",
    "#it will return 0.00 \n",
    "def spatial_resolution(raster):\n",
    "    \"\"\"extracts the XY Pixel Size\"\"\"\n",
    "    t = raster.transform\n",
    "    x = t[0]\n",
    "    y = -t[4]\n",
    "    x_trunc = trun_n_d(x, 3)\n",
    "    y_trunc = trun_n_d(y, 3)\n",
    "    return x_trunc, y_trunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf773eff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "###########Function to calculate the bounding box and footprint of a geospatial raster dataset\n",
    "######################\n",
    "\n",
    "#This creates a function called 'get_bbox_and_footprint' for a raster we are calling 'dataset'\n",
    "def get_bbox_and_footprint(dataset):\n",
    "\n",
    "    # extract the bounding box of a raster using rasterio. '.bounds' is an attribute of 'rasterio.DatasetReader'\n",
    "    #'bounds' returns the left, bottom, right, and top coordinates of a raster\n",
    "    bounds = dataset.bounds\n",
    "    \n",
    "    #Transform the coordinate system of the raster bounds from it's orginial coordinate reference system \\\n",
    "    #to wgs84 which is also known as EPSG 4326. It uses the rasterio submodule 'rasterio.warp'\n",
    "    bounds = rasterio.warp.transform_bounds(dataset.crs, 'EPSG:4326', \n",
    "                                            bounds.left, bounds.bottom, bounds.right, bounds.top)\n",
    "   \n",
    "    #The transformed bounds are then used to create a new rasterio.coords.BoundingBox object. \\\n",
    "    #The rasterio.coords.BoundingBox class is a convenient way to represent a bounding box \\\n",
    "    #with named attributes (left, bottom, right, and top) instead of using a tuple or a list. \\\n",
    "    #This makes the code more readable and easier to work with.\n",
    "    bounds = rasterio.coords.BoundingBox(bounds[0], bounds[1], bounds[2], bounds[3])\n",
    "    \n",
    "    \n",
    "    #The isinstance() function checks if the bounds variable is an instance of the \\\n",
    "    #rasterio.coords.BoundingBox class. If it is, it means that the bounds variable \\\n",
    "    #represents a bounding box with named attributes (left, bottom, right, and top).\n",
    "    #If the bounds variable is an instance of rasterio.coords.BoundingBox, \\\n",
    "    #the code creates a list called bbox, which contains the bounding box coordinates \\\n",
    "    #in the following order: left, bottom, right, and top. This list is a more straightforward \\\n",
    "    #way to represent the bounding box as a sequence of coordinates.\n",
    "    if isinstance(bounds, rasterio.coords.BoundingBox):\n",
    "        bbox = [bounds.left, bounds.bottom, bounds.right, bounds.top]\n",
    "        \n",
    "    #If the bounds variable is not an instance of rasterio.coords.BoundingBox, \\\n",
    "    #the code assumes that it is a callable object (such as a function or a method) \\\n",
    "    #that returns the bounding box coordinates when called. In this case, the code \\\n",
    "    #calls the bounds() function and converts the returned bounding box coordinates \\\n",
    "    #to a list of floating-point numbers. This list is then assigned to the bbox variable.    \n",
    "    else:\n",
    "        bbox = [float(f) for f in bounds()]\n",
    "\n",
    "    # create vertices and polygon from the bounding box coordinates. It uses the 'shapely.geometry' module \\\n",
    "    #from the shapely library. The output is the'footprint' variable which contains a shapely.geometry.Polygon object \\\n",
    "    #that represents the footprint of the raster dataset, based on its bounding box coordinates. \\\n",
    "    #This footprint can be used for tasks like spatial analysis, visualization, or overlaying with other geospatial data.\n",
    "    footprint = Polygon([\n",
    "        [bbox[0], bbox[1]],#left bottom\n",
    "        [bbox[0], bbox[3]],#left top\n",
    "        [bbox[2], bbox[3]],#right top\n",
    "        [bbox[2], bbox[1]] #right bottom\n",
    "    ])\n",
    "    \n",
    "    #Return the calculated bbox and the footprint as a dictionary using the mapping function \\\n",
    "    #(from the shapely.geometry module)\n",
    "    return bbox, mapping(footprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da79f558-e5ba-48fa-b48b-cc3c14602092",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Function to get the spatial information on tiff imagery products\n",
    "\n",
    "def tif_get_spatial_info(tif_file_path: Path) -> Optional[tuple]:\n",
    "\n",
    "    # Open the individual file with rasterio\n",
    "    ds = rasterio.open(tif_file_path)\n",
    "\n",
    "    # Apply the function to get the bounding box (left, bottom, right, top) and make a footprint rectangle\n",
    "    bbox, footprint = get_bbox_and_footprint(ds)\n",
    "\n",
    "    # Extract the spatial resolution (gsd) of the image product using the function 'spatial_resolution'.\n",
    "    x_res, y_res = spatial_resolution(ds)\n",
    "\n",
    "    # Return the path, bounding box, the footprint, and the X and Y GSD (Ground Sample Distance)\n",
    "    return tif_file_path, bbox, footprint, x_res, y_res, ds.shape, ds.crs.to_epsg(), pystac.MediaType.COG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35c0bfa3-9367-4710-b3cb-eedc9c67a6a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Determines the GSD (ground sampling distance) of an LAS/LAZ file\n",
    "\n",
    "def las_spatial_resolution(bounding_box: tuple, num_points: int) -> tuple:\n",
    "    \n",
    "    min_y, min_x, max_y, max_x = bounding_box\n",
    "\n",
    "    gsd_x = geodesic((min_x, min_y), (max_x, min_y)).meters / float(num_points)\n",
    "    gsd_y = geodesic((min_x, min_y), (min_x, max_y)).meters / float(num_points)\n",
    "    \n",
    "    return gsd_x, gsd_y"
   ]
  },
  {
   "cell_type": "raw",
   "id": "32d4b4d9-b7de-43d6-a3b4-66c8d5808d07",
   "metadata": {
    "tags": []
   },
   "source": [
    "###This is a function to extract the timestamp of a raw drone image from the exif data embedded on the image\n",
    "\n",
    "\n",
    "def exif_to_timestamp(file_path):\n",
    "     EXIF tags to look for\n",
    "    EXIF_ORIGIN_TIMESTAMP = 36867         # Capture timestamp\n",
    "    EXIF_TIMESTAMP_OFFSET = 36881         # Timestamp UTC offset (general)\n",
    "    EXIF_ORIGIN_TIMESTAMP_OFFSET = 36881  # Capture timestamp UTC offset\n",
    "\n",
    "    cur_stamp, cur_offset = (None, None)\n",
    "\n",
    "    # try to load EXIF data\n",
    "    exif_tags = piexif.load(file_path)\n",
    "    if not exif_tags or \"Exif\" not in exif_tags:\n",
    "        return None\n",
    "    \n",
    "    def convert_and_clean_tag(value):\n",
    "         internal helper function for handling EXIF tag values\n",
    "        if not value:\n",
    "            return None\n",
    "\n",
    "        # Convert bytes to string\n",
    "        if isinstance(value, bytes):\n",
    "            value = value.decode('UTF-8').strip()\n",
    "        else:\n",
    "            value = value.strip()\n",
    "\n",
    "        # Check for an empty string after stripping colons\n",
    "        if value:\n",
    "            if not value.replace(\":\", \"\").replace(\"+:\", \"\").replace(\"-\", \"\").strip():\n",
    "                value = None\n",
    "\n",
    "        return None if not value else value\n",
    "\n",
    "    # Process the EXIF data\n",
    "    if EXIF_ORIGIN_TIMESTAMP in exif_tags:\n",
    "        cur_stamp = convert_and_clean_tag(exif_tags[EXIF_ORIGIN_TIMESTAMP])\n",
    "    if not cur_stamp:\n",
    "        return None\n",
    "\n",
    "    if EXIF_ORIGIN_TIMESTAMP_OFFSET in exif_tags:\n",
    "        cur_offset = convert_and_clean_tag(exif_tags[EXIF_ORIGIN_TIMESTAMP_OFFSET])\n",
    "    if not cur_offset and EXIF_TIMESTAMP_OFFSET in exif_tags:\n",
    "        cur_offset = convert_and_clean_tag(exif_tags[EXIF_TIMESTAMP_OFFSET])\n",
    "\n",
    "    # Format the string to a timestamp and return the result\n",
    "    try:\n",
    "        if not cur_offset:\n",
    "            cur_ts = datetime.datetime.fromisoformat(cur_stamp)\n",
    "        else:\n",
    "            cur_offset = cur_offset.replace(\":\", \"\")\n",
    "            cur_ts = datetime.datetime.fromisoformat(cur_stamp + cur_offset)\n",
    "    except Exception as ex:\n",
    "        cur_ts = None\n",
    "        print(\"Exception caught converting EXIF tag to timestamp: %s\", str(ex))\n",
    "\n",
    "    return cur_ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ea6ec7c-9405-4350-a305-d0d74a9c97b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "####Returns the bounding box, footprint, and EPSG of the passed in LAS/LAZ file content\n",
    "\n",
    "def get_las_bbox_footprint(las_srs_wkt: str, boundary_wkt: str, target_epsg: int=4326) -> list:\n",
    "    # Returns a list containing the bounding box, and footprint geometries\n",
    "    \n",
    "    bounds_polygon = ogr.CreateGeometryFromWkt(boundary_wkt)\n",
    "\n",
    "    # Translate the points if needed\n",
    "    src_srs = osr.SpatialReference()\n",
    "    src_srs.ImportFromWkt(las_srs_wkt)\n",
    "\n",
    "    geom_epsg = int(src_srs.GetAttrValue('AUTHORITY', 1))\n",
    "    if geom_epsg != target_epsg:\n",
    "        # Set up the transformation\n",
    "        dst_srs = osr.SpatialReference()\n",
    "        dst_srs.ImportFromEPSG(target_epsg)\n",
    "\n",
    "        transform = osr.CoordinateTransformation(src_srs, dst_srs)\n",
    "        \n",
    "        # Perform the transformation\n",
    "        transl_polygon = bounds_polygon.Clone()\n",
    "        transl_polygon.Transform(transform)\n",
    "        \n",
    "        bounds_polygon = transl_polygon\n",
    "\n",
    "    # Get the envelope of the polygon and re-arrange to expected order\n",
    "    return_bbox = bounds_polygon.GetEnvelope()\n",
    "    return_bbox = (return_bbox[2], return_bbox[0], return_bbox[3], return_bbox[1])\n",
    "\n",
    "    # Create the polygon of the footprint\n",
    "    footprint = Polygon([\n",
    "        [return_bbox[0], return_bbox[1]],#left bottom\n",
    "        [return_bbox[0], return_bbox[3]],#left top\n",
    "        [return_bbox[2], return_bbox[3]],#right top\n",
    "        [return_bbox[2], return_bbox[1]] #right bottom\n",
    "    ])\n",
    "\n",
    "    return return_bbox, footprint, geom_epsg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e134486-1d96-4f81-9df7-ab1983fe2db2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "####Function to get the spatial information on the point cloud files\n",
    "\n",
    "#Return the information on the LAS/LAZ files\n",
    "def las_get_spatial_info(las_file_path: Path) -> Optional[tuple]:\n",
    "\n",
    "    # Folder to write temporary files to\n",
    "    root_dir = '/tmp'\n",
    "        \n",
    "    # Configure the processing pipeline for the data we will want\n",
    "    pipeline_json  = \"\"\"\n",
    "    {\n",
    "        \"pipeline\": [\n",
    "            \"%s\",\n",
    "            {\n",
    "                \"type\" : \"filters.hexbin\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \"\"\" % las_file_path\n",
    "\n",
    "    # Get the filenames for the pipeline text, and the output of the pipeline\n",
    "    base_filename, file_ext = os.path.splitext(os.path.basename(las_file_path))\n",
    "    pipeline_path = os.path.join(root_dir, base_filename + '_pipeline.json')\n",
    "    out_path = os.path.join(root_dir, base_filename + '.json')\n",
    "    with open(pipeline_path, \"w\") as outfile:\n",
    "        outfile.write(pipeline_json)\n",
    "\n",
    "    # Make the call to run the pdal app to process the pipeline\n",
    "    result = subprocess.run(['/opt/conda/envs/osgeo/bin/pdal', 'pipeline', pipeline_path, '--metadata', out_path], stdout=subprocess.PIPE,\n",
    "                           stderr=subprocess.PIPE)\n",
    "\n",
    "    # Load the output of the pipeline\n",
    "    with open(out_path, 'r') as infile:\n",
    "        metadata = json.load(infile)\n",
    "\n",
    "    # Clean up the temporary files\n",
    "    os.remove(pipeline_path)\n",
    "    os.remove(out_path)\n",
    "\n",
    "    # Assign to variable to make it easier for a developer\n",
    "    readers = metadata['stages']['readers.las']\n",
    "    hexbin = metadata['stages']['filters.hexbin']\n",
    "\n",
    "    # Get the bounding box in the correct coordinate system\n",
    "    bbox, footprint, epsg = get_las_bbox_footprint(readers['srs']['wkt'], hexbin['boundary'])\n",
    "\n",
    "    # Extract the spatial resolution (gsd) of the image product using the function 'las_spatial_resolution'.\n",
    "    x_res, y_res = las_spatial_resolution(bbox, readers['count'])\n",
    "\n",
    "    # Return the path, bounding box, the footprint, and the X and Y GSD (Ground Sample Distance)\n",
    "    return las_file_path, bbox, mapping(footprint), x_res, y_res, (None, None), epsg, 'application/vnd.laszip' if file_ext == '.laz' else 'application/vnd.las'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55127d71-6a40-4079-9052-cecfc9b7276a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done processing files\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###This starts the for loop to crawl through a folder, find imagery assets, and generate STAC json metadata files for each item\n",
    "\n",
    "os.environ['PROJ_DATA'] = '/opt/conda/envs/osgeo/share/proj'\n",
    "\n",
    "# Disable a warning message\n",
    "ogr.UseExceptions()\n",
    "\n",
    "# Get a list of geospatial files (in this case located in Cyverse data store)\n",
    "folder = Path(source_image_folder)\n",
    "\n",
    "\n",
    "# Create an extension mapping dictionary to assist with the file discovery and multithreading\n",
    "# Each extension maps to the function to call\n",
    "ext_map = {'.tif': tif_get_spatial_info,\n",
    "           '.las': las_get_spatial_info,\n",
    "           '.laz': las_get_spatial_info\n",
    "          }\n",
    "\n",
    "# Load the files of interest\n",
    "files = list()\n",
    "for one_filter in ext_map.keys():\n",
    "    files = files + list(folder.rglob('*' + one_filter))\n",
    "\n",
    "# Initialize variables to hold the results\n",
    "items_dict = {}\n",
    "all_items = []\n",
    "\n",
    "# Create a ThreadPoolExecutor with 2 worker threads to load all the spatial data\n",
    "with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    # Submit each file to the executor using the file extension to determine which function to call\n",
    "    future_results = [executor.submit(ext_map[os.path.splitext(file)[1]], file) for file in files]\n",
    "\n",
    "    # Get the results as they become available\n",
    "    all_results = [future.result() for future in future_results]\n",
    "\n",
    "    \n",
    "# Loop through each item in the folder and do several things\n",
    "for result in all_results:\n",
    "\n",
    "    #Get the specific results from processing one file\n",
    "    file, bbox, footprint, x_res, y_res, width_height, srid, media_type = result\n",
    "\n",
    "    # the ID (name) for each indivual file\n",
    "    idx = file.stem\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##The following 3 lines are for assigning the date of imagery collection to each of the item by matching IDs from a csv file\n",
    "    \n",
    "    \n",
    "    # Within the for loop that we are in, this line looks at the 'Id' column of the csv file (imported into python as a pandas DataFrame).\n",
    "    # It takes the Id name of the current geotiff file and looks for a match within the Id column within 'df_collection_date'. \n",
    "    # If it finds a matching ID, it returns the info for the entire row. IDs in the dataframe are stored as strings. \n",
    "    \n",
    "    collection_time = df_collection_date[df_collection_date.Id == str(idx)]\n",
    "    \n",
    "    # From the matched row, this command will return the value within the 'collection_date' column as a 2D numpy array \n",
    "    dates = collection_time.collection_date.values\n",
    "    \n",
    "    # Get the plot name of the item\n",
    "    plot = collection_time['plot'].iloc[0]\n",
    "    \n",
    "    # Convert the date into a 'datetime' object (e.g., 2019-05-19)\n",
    "    datess = datetime.strptime(dates[0], '%Y-%m-%d')\n",
    "\n",
    "    # Check if an item with this plot name already exists\n",
    "    if plot in items_dict:\n",
    "        #if it does, get that item\n",
    "        item = items_dict[plot]\n",
    "        \n",
    "    # If this is an item with a new plot name \n",
    "    else:    \n",
    "        # create a STAC item for each individual file \n",
    "        item = pystac.Item(id=plot,\n",
    "                geometry=footprint,\n",
    "                bbox=bbox,\n",
    "                datetime=datess,\n",
    "                #datetime=default_datetime,\n",
    "                stac_extensions=['https://stac-extensions.github.io/projection/v1.0.0/schema.json',\n",
    "                                 'https://stac-extensions.github.io/scientific/v1.0.0/schema.json'],\n",
    "                 \n",
    "                properties={'gsd': x_res,\n",
    "                        'platform': platform,\n",
    "                        'license': license,\n",
    "                        'mission': items_mission_description,\n",
    "                        'sci:doi': pub_doi,\n",
    "                        'sci:citation': citation,\n",
    "                        'providers': [provider_dict]}\n",
    "        )\n",
    "    items_dict[plot] = item\n",
    "    \n",
    "    # Adding the map projection extension to each item. Otherwise, the projection info will not display \n",
    "    params = {\n",
    "        'bbox': bbox,\n",
    "        'geometry': footprint\n",
    "        }\n",
    "    if None not in width_height:\n",
    "        params['shape'] = width_height  #ds.shape,\n",
    "    ProjectionExtension.ext(item).apply(srid, #ds.crs.to_epsg(),\n",
    "                                        **params)\n",
    "                                        #transform = [float(getattr(ds.transform, letter)) for letter in 'abcdef']\n",
    "                                        #)\n",
    "   \n",
    "    # Add the asset link to the item and define the type of geospatial format it is\n",
    "    item.add_asset(\n",
    "        key=idx,\n",
    "        asset=pystac.Asset(\n",
    "            href=file.as_posix(), \n",
    "            media_type=media_type, #pystac.MediaType.COG\n",
    "            roles='data'\n",
    "            #extra_fields=asset_ext\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Add each STAC item to a list of all the items\n",
    "    all_items.append(item)\n",
    "    all_items = list(items_dict.values())\n",
    "\n",
    "print('Done processing files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5e85be0-75fd-4d24-819b-edfba3e1636c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######Create and describe a STAC Collection \n",
    "##########################\n",
    "\n",
    "# the geographic extent of all the items added\n",
    "item_extents = pystac.Extent.from_items(all_items)\n",
    "\n",
    "# creating the collection\n",
    "collection = pystac.Collection(id=collection_id,\n",
    "                               description=collection_description,\n",
    "                               extent=item_extents,\n",
    "                               license=license)\n",
    "\n",
    "# add all STAC item to the STAC collection\n",
    "for item in all_items:\n",
    "    collection.add_item(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c5c6066-1ed9-4808-8c83-d26bfd07dd3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "* <Collection id=ofo_test>\n",
      "  * <Item id=15_g2>\n"
     ]
    }
   ],
   "source": [
    "# print the number of STAC items that were added to the STAC catalog    \n",
    "print(len(list(collection.get_items())))\n",
    "\n",
    "# describe the items in the STAC catalog\n",
    "collection.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f141a439-0cf6-41fc-81dd-3656fcf164c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##########Save the collection and its child items to output directory (ABSOLUTE LINKS FOR STAC API)\n",
    "\n",
    "collection.normalize_hrefs(stac_output_directory)\n",
    "\n",
    "collection.save(catalog_type=pystac.CatalogType.ABSOLUTE_PUBLISHED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "746ce45b-02af-4523-ab4e-f03cf10cd506",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#########Combine all of the STAC item metadata into a single geojson and output to directory\n",
    "####################\n",
    "\n",
    "# Create an empty GeoJSON FeatureCollection\n",
    "geojson = {\n",
    "    \"type\": \"FeatureCollection\",\n",
    "    \"features\": []\n",
    "}\n",
    "\n",
    "# Iterate through all the items in the collection and convert them to GeoJSON Features\n",
    "for item in collection.get_all_items():\n",
    "    # Get the STAC Item as a dictionary\n",
    "    item_dict = item.to_dict()\n",
    "\n",
    "    # Convert the STAC Item to a GeoJSON Feature\n",
    "    feature = {\n",
    "        \"type\": \"Feature\",\n",
    "        \"collection\": item_dict[\"collection\"],\n",
    "        \"stac_version\": item_dict[\"stac_version\"],\n",
    "        \"stac_extensions\": item_dict[\"stac_extensions\"],\n",
    "        \"id\": item_dict[\"id\"],\n",
    "        \"geometry\": item_dict[\"geometry\"],\n",
    "        \"bbox\": item_dict[\"bbox\"],\n",
    "        \"properties\": item_dict[\"properties\"],\n",
    "        \"assets\": item_dict[\"assets\"]\n",
    "    }\n",
    "\n",
    "    # Add the GeoJSON Feature to the FeatureCollection\n",
    "    geojson[\"features\"].append(feature)\n",
    "\n",
    "\n",
    "# Make sure the output_directory ends with a path separator\n",
    "if not stac_output_directory.endswith(\"/\"):\n",
    "    stac_output_directory += \"/\"\n",
    "\n",
    "output_file_path = stac_output_directory + \"index.geojson\"\n",
    "\n",
    "# Write the GeoJSON FeatureCollection to a file\n",
    "with open(output_file_path, \"w\") as f:\n",
    "    json.dump(geojson, f, indent=4)        \n",
    "\n",
    "    \n",
    "\n",
    "# Define the string to find and the string to replace it with\n",
    "string_to_find = \"/data-store\"\n",
    "string_to_replace = \"https://data.cyverse.org/dav-anon\"\n",
    "\n",
    "# Read the file into a string\n",
    "with open(output_file_path, \"r\") as f:\n",
    "    file_content = f.read()\n",
    "\n",
    "# Perform the find-and-replace operation\n",
    "file_content = file_content.replace(string_to_find, string_to_replace)\n",
    "\n",
    "# Write the result back to the file\n",
    "with open(output_file_path, \"w\") as f:\n",
    "    f.write(file_content)\n",
    "    \n",
    "    \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "065f6bb6-2f9f-4c59-85b2-e239936ec42e",
   "metadata": {
    "tags": []
   },
   "source": [
    "########Save the collection and it's child items with RELATIVE LINKS FOR STATIC CATALOG\n",
    "\n",
    "collection.normalize_hrefs(stac_output_directory)\n",
    "\n",
    "collection.make_all_asset_hrefs_relative()\n",
    "\n",
    "collection.save(catalog_type=pystac.CatalogType.SELF_CONTAINED)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1b583040-a985-454c-966c-624e88842e96",
   "metadata": {
    "tags": []
   },
   "source": [
    "# create a STAC catalog instance using pystac. Do this for Static Catalogs, not for STAC API\n",
    "catalog = pystac.Catalog(\n",
    "    id=catalog_id,\n",
    "    description=catalog_description,\n",
    "    stac_extensions=['https://stac-extensions.github.io/projection/v1.0.0/schema.json']\n",
    ")    \n",
    "\n",
    "#add the collection to the catalog\n",
    "catalog.add_child(collection)\n",
    "\n",
    "# print the number of STAC items that were added to the STAC catalog    \n",
    "print(len(list(collection.get_items())))\n",
    "\n",
    "# describe the items in the STAC catalog\n",
    "catalog.describe()\n",
    "\n",
    "# write the STAC catalog out (RELATIVE LINKS FOR STATIC CATALOG)\n",
    "catalog.normalize_hrefs(stac_output_directory)\n",
    "\n",
    "catalog.make_all_asset_hrefs_relative()\n",
    "catalog.save(catalog_type=pystac.CatalogType.SELF_CONTAINED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b4d692",
   "metadata": {
    "raw_mimetype": "text/markdown",
    "tags": []
   },
   "source": [
    "To make the saved catalog available, you will need to:\n",
    "-  share the output folder to \\\"public\\\" using the [Discovery Environment](https://de.cyverse.org/) Data tab\n",
    "- add your catalog to the CyVerse [master catalog](/iplant/home/jgillan/stac.cyverse.org/cyverse_stac_catalog/catalog.json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65966c71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%pip install python-irodsclient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a28bd8a",
   "metadata": {
    "tags": []
   },
   "source": [
    "The following will share the folder containing your catalog with the CyVerse `public` user using read-only permissions\n",
    "\n",
    "You will be prompted to enter your CyVerse username and password. Be sure to use the *Enter* key for each prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edb6ab5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "#from getpass import getpass\n",
    "#from irods.access import iRODSAccess\n",
    "#from irods.session import iRODSSession\n",
    "\n",
    "#irods_username = input('Enter your CyVerse user name:')\n",
    "#irods_password = getpass('Enter your CyVerse password:')\n",
    "\n",
    "#sess = iRODSSession(host='data.cyverse.org', port=1247, user=irods_username, password=irods_password, zone='iplant')\n",
    "\n",
    "#user = sess.users.get(sess.username, sess.zone)\n",
    "\n",
    "# add the needed users for linking\n",
    "#acl_path = '/' + os.path.join(*(stac_output_directory.split(os.path.sep)[2:]))\n",
    "#acl = iRODSAccess('read', acl_path, 'anonymous', user.zone)\n",
    "#sess.acls.set(acl, recursive=True)\n",
    "\n",
    "#sess.cleanup()\n",
    "\n",
    "#print(\"Folder updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f111a5b",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Almost Done!**\n",
    "\n",
    "To have a *newly created* catalog added to the global CyVerse catalog, update `your_email` using your email address\n",
    "and send an email using the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ae72d1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#your_email = '<someone>@arizona.edu'\n",
    "\n",
    "# Import smtplib for the actual sending function\n",
    "#import smtplib\n",
    "\n",
    "# Import the email modules we'll need\n",
    "#from email.mime.text import MIMEText\n",
    "\n",
    "#msg = MIMEText(\"Please add the following STAC catalog to the main CyVerse catalog: \" + \n",
    "               #\"https://data.cyverse.org/dav-anon/\" + os.path.join(*(stac_output_directory.split(os.path.sep)[2:])) +\n",
    "               #\"/catalog.json\")\n",
    "#msg['Subject'] = 'Add new STAC catalog to main CyVerse catalog'\n",
    "#msg['From'] = your_email\n",
    "#msg['To'] = contact_email\n",
    "\n",
    "# Send the message via our own SMTP server, but don't include the\n",
    "# envelope header.\n",
    "#smtp = smtplib.SMTP(smtp_host)\n",
    "#smtp.sendmail(your_email, [contact_email], msg.as_string())\n",
    "#smtp.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osgeo",
   "language": "python",
   "name": "osgeo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
